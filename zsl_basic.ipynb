{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from sklearn.preprocessing import LabelEncoder, normalize\n",
    "from sklearn.neighbors import KDTree\n",
    "import pickle\n",
    "import numpy as np\n",
    "import gzip\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \"\"\"Get image feature extraction model from pre-trained vgg16 model.\"\"\"\n",
    "    vgg_model = models.vgg16(pretrained=True)\n",
    "    vgg_model.classifier = nn.Sequential(*list(vgg16.classifier.children())[:-2])\n",
    "    return vgg_model\n",
    "\n",
    "def get_features(model, cropped_image):\n",
    "    \"\"\"Extract features from image using given model.\"\"\"\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    x = preprocess(cropped_image)\n",
    "    x = x.unsqueeze(0)\n",
    "    features = model(x)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloVe():\n",
    "\n",
    "    def __init__(self, file_path):\n",
    "        self.dimension = None\n",
    "        self.embedding = dict()\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                strs = line.strip().split()\n",
    "                word = strs[0]\n",
    "                vector = torch.FloatTensor(list(map(float, strs[1:])))\n",
    "                self.embedding[word] = vector\n",
    "                if self.dimension is None:\n",
    "                    self.dimension = len(vector)\n",
    "\n",
    "    def _fix_word(self, word):\n",
    "        terms = word.replace('_', ' ').split(' ')\n",
    "        ret = self.zeros()\n",
    "        cnt = 0\n",
    "        for term in terms:\n",
    "            v = self.embedding.get(term)\n",
    "            if v is None:\n",
    "                subterms = term.split('-')\n",
    "                subterm_sum = self.zeros()\n",
    "                subterm_cnt = 0\n",
    "                for subterm in subterms:\n",
    "                    subv = self.embedding.get(subterm)\n",
    "                    if subv is not None:\n",
    "                        subterm_sum += subv\n",
    "                        subterm_cnt += 1\n",
    "                if subterm_cnt > 0:\n",
    "                    v = subterm_sum / subterm_cnt\n",
    "            if v is not None:\n",
    "                ret += v\n",
    "                cnt += 1\n",
    "        return ret / cnt if cnt > 0 else None\n",
    "\n",
    "    def __getitem__(self, words):\n",
    "        if type(words) is str:\n",
    "            words = [words]\n",
    "        ret = self.zeros()\n",
    "        cnt = 0\n",
    "        for word in words:\n",
    "            v = self.embedding.get(word)\n",
    "            if v is None:\n",
    "                v = self._fix_word(word)\n",
    "            if v is not None:\n",
    "                ret += v\n",
    "                cnt += 1\n",
    "        if cnt > 0:\n",
    "            return ret / cnt\n",
    "        else:\n",
    "            return self.zeros()\n",
    "    \n",
    "    def zeros(self):\n",
    "        return torch.zeros(self.dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove = GloVe('materials/glove.6B.300d.txt')\n",
    "glove['name'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('materials/train_classes.txt', 'r') as infile:\n",
    "    train_classes = [str.strip(line) for line in infile]\n",
    "\n",
    "with open('materials/zsl_classes.txt', 'r') as infile:\n",
    "    zsl_classes = [str.strip(line) for line in infile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes):\n",
    "    return np.eye(num_classes, dtype='uint8')[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    \"\"\"read data, create datasets.\n",
    "    \n",
    "    Data is the pre-trained vgg model feature outputs.\n",
    "    \"\"\"\n",
    "    # READ DATA\n",
    "    with gzip.GzipFile(data_path, 'rb') as infile:\n",
    "        data = pickle.load(infile)\n",
    "\n",
    "    # ONE-HOT-ENCODE DATA\n",
    "    label_encoder   = LabelEncoder()\n",
    "    label_encoder.fit(train_classes)\n",
    "\n",
    "    training_data = [instance for instance in data if instance[0] in train_classes]\n",
    "    zero_shot_data = [instance for instance in data if instance[0] not in train_classes]\n",
    "    # SHUFFLE TRAINING DATA\n",
    "    np.random.shuffle(training_data)\n",
    "\n",
    "    ### SPLIT DATA FOR TRAINING\n",
    "    train_size  = 300\n",
    "    train_data  = list()\n",
    "    valid_data  = list()\n",
    "    for class_label in train_classes:\n",
    "        ct = 0\n",
    "        for instance in training_data:\n",
    "            if instance[0] == class_label:\n",
    "                if ct < train_size:\n",
    "                    train_data.append(instance)\n",
    "                    ct+=1\n",
    "                    continue\n",
    "                valid_data.append(instance)\n",
    "\n",
    "    # SHUFFLE TRAINING AND VALIDATION DATA\n",
    "    np.random.shuffle(train_data)\n",
    "    np.random.shuffle(valid_data)\n",
    "\n",
    "    train_data = [(instance[1], to_categorical(label_encoder.transform([instance[0]]), num_classes=15))for instance in train_data]\n",
    "    valid_data = [(instance[1], to_categorical(label_encoder.transform([instance[0]]), num_classes=15)) for instance in valid_data]\n",
    "\n",
    "    # FORM X_TRAIN AND Y_TRAIN\n",
    "    x_train, y_train    = zip(*train_data)\n",
    "    x_train, y_train    = np.squeeze(np.asarray(x_train)), np.squeeze(np.asarray(y_train))\n",
    "    # L2 NORMALIZE X_TRAIN\n",
    "    x_train = normalize(x_train, norm='l2')\n",
    "\n",
    "    # FORM X_VALID AND Y_VALID\n",
    "    x_valid, y_valid = zip(*valid_data)\n",
    "    x_valid, y_valid = np.squeeze(np.asarray(x_valid)), np.squeeze(np.asarray(y_valid))\n",
    "    # L2 NORMALIZE X_VALID\n",
    "    x_valid = normalize(x_valid, norm='l2')\n",
    "\n",
    "\n",
    "    # FORM X_ZSL AND Y_ZSL\n",
    "    y_zsl, x_zsl = zip(*zero_shot_data)\n",
    "    x_zsl, y_zsl = np.squeeze(np.asarray(x_zsl)), np.squeeze(np.asarray(y_zsl))\n",
    "    # L2 NORMALIZE X_ZSL\n",
    "    x_zsl = normalize(x_zsl, norm='l2')\n",
    "\n",
    "    print(\"-> data loading is completed.\")\n",
    "    return (x_train, x_valid, x_zsl), (y_train, y_valid, y_zsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> data loading is completed.\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASS = 15\n",
    "NUM_ATTR = 300\n",
    "BATCH_SIZE = 128\n",
    "EPOCH = 1000\n",
    "DATA_PATH = 'materials/zeroshot_data.pkl'\n",
    "\n",
    "(x_train, x_valid, x_zsl), (y_train, y_valid, y_zsl) = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \"\"\"We set the weights of final layer to the embedding value of labels,\n",
    "    then use them to compare with the image features.\"\"\"\n",
    "    \n",
    "    final_untrained_fc = nn.Linear(NUM_ATTR, NUM_CLASS, bias=False)\n",
    "    final_untrained_af = nn.Softmax(dim=1)\n",
    "\n",
    "    class_vectors = np.load('materials/class_vectors.npy', allow_pickle=True)\n",
    "    training_vectors    = sorted([(label, vec) for (label, vec) in class_vectors if label in train_classes], key=lambda x: x[0])\n",
    "    classnames, vectors = zip(*training_vectors)\n",
    "    vectors             = np.asarray(vectors, dtype=np.float32)\n",
    "\n",
    "    for p in final_untrained_fc.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in final_untrained_af.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    with torch.no_grad():\n",
    "        final_untrained_fc.weight.data = torch.from_numpy(vectors)\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(4096, 1024),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(1024),\n",
    "        nn.Dropout(0.8),\n",
    "        nn.Linear(1024, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, NUM_ATTR),\n",
    "        nn.ReLU(),\n",
    "        final_untrained_fc,\n",
    "        final_untrained_af,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, valid_data):\n",
    "    x_train, y_train = train_data\n",
    "    x_valid, y_valid = valid_data\n",
    "    x_valid, y_valid = torch.from_numpy(x_valid), torch.from_numpy(y_valid)\n",
    "    optimizer = torch.optim.Adam(lr=1e-5, params=model.parameters())\n",
    "    rng = np.random.default_rng()\n",
    "\n",
    "    for epoch in range(10000):\n",
    "        rints = rng.integers(low=0, high=len(y_train), size=BATCH_SIZE)\n",
    "        x_train_batch, y_train_batch = x_train[rints], y_train[rints]\n",
    "        x_train_batch, y_train_batch = torch.from_numpy(x_train_batch), torch.from_numpy(y_train_batch)\n",
    "        optimizer.zero_grad()\n",
    "        y_train_batch_pred = model(x_train_batch)\n",
    "        loss = nn.CrossEntropyLoss()(y_train_batch_pred, torch.max(y_train_batch, 1)[1])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 1000 == 0:\n",
    "            print('Training Loss: {}'.format(loss.item()))\n",
    "            with torch.no_grad():\n",
    "                y_valid_pred = model(x_valid)\n",
    "                loss = nn.CrossEntropyLoss()(y_valid_pred, torch.max(y_valid, 1)[1])\n",
    "            print('Validation Loss: {}'.format(loss.mean().item()))\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.709284543991089\n",
      "Validation Loss: 2.708547830581665\n",
      "Training Loss: 2.3672308921813965\n",
      "Validation Loss: 2.3981149196624756\n",
      "Training Loss: 2.1713616847991943\n",
      "Validation Loss: 2.3326947689056396\n",
      "Training Loss: 2.125985622406006\n",
      "Validation Loss: 2.304955005645752\n",
      "Training Loss: 2.056572675704956\n",
      "Validation Loss: 2.2991750240325928\n",
      "Training Loss: 2.002394437789917\n",
      "Validation Loss: 2.2781758308410645\n",
      "Training Loss: 1.984486699104309\n",
      "Validation Loss: 2.2689290046691895\n",
      "Training Loss: 1.9162209033966064\n",
      "Validation Loss: 2.2736241817474365\n",
      "Training Loss: 1.9294459819793701\n",
      "Validation Loss: 2.2614598274230957\n",
      "Training Loss: 1.9332287311553955\n",
      "Validation Loss: 2.270838499069214\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "train_model(model, (x_train, y_train), (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use wordnet to generate label embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ZERO SHOT LEARNING SCORE\n",
      "-> Top-5 Accuracy: 0.54\n",
      "-> Top-3 Accuracy: 0.25\n",
      "-> Top-1 Accuracy: 0.00\n"
     ]
    }
   ],
   "source": [
    "zsl_model = nn.Sequential(*list(model.children())[:-2])\n",
    "\n",
    "# EVALUATION OF ZERO-SHOT LEARNING PERFORMANCE\n",
    "WORD2VECPATH = 'materials/class_vectors.npy'\n",
    "class_vectors       = sorted(np.load(WORD2VECPATH, allow_pickle=True), key=lambda x: x[0])\n",
    "classnames, vectors = zip(*class_vectors)\n",
    "classnames          = list(classnames)\n",
    "vectors             = np.asarray(vectors, dtype=np.float)\n",
    "\n",
    "tree        = KDTree(vectors)\n",
    "pred_zsl    = zsl_model(torch.from_numpy(x_zsl))\n",
    "\n",
    "pred_zsl = pred_zsl.detach().numpy()\n",
    "top5, top3, top1 = 0, 0, 0\n",
    "\n",
    "for i, pred in enumerate(pred_zsl):\n",
    "    pred = np.expand_dims(pred, axis=0)\n",
    "    dist_5, index_5 = tree.query(pred, k=5)\n",
    "    pred_labels = [classnames[index] for index in index_5[0]]\n",
    "    true_label = y_zsl[i]\n",
    "\n",
    "    if true_label in pred_labels:\n",
    "        top5 += 1\n",
    "    if true_label in pred_labels[:3]:\n",
    "        top3 += 1\n",
    "    if true_label in pred_labels[0:1]:\n",
    "        top1 += 1\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"ZERO SHOT LEARNING SCORE\")\n",
    "print(\"-> Top-5 Accuracy: %.2f\" % (top5 / float(len(x_zsl))))\n",
    "print(\"-> Top-3 Accuracy: %.2f\" % (top3 / float(len(x_zsl))))\n",
    "print(\"-> Top-1 Accuracy: %.2f\" % (top1 / float(len(x_zsl))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use GloVe to generate label embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_glove_model():\n",
    "    \"\"\"We set the weights of final layer to the embedding value of labels,\n",
    "    then use them to compare with the image features.\"\"\"\n",
    "    \n",
    "    final_untrained_fc = nn.Linear(NUM_ATTR, NUM_CLASS, bias=False)\n",
    "    final_untrained_af = nn.Softmax(dim=1)\n",
    "\n",
    "    training_vectors = []\n",
    "    for train_class in train_classes:\n",
    "        training_vectors.append(glove[train_class].unsqueeze(dim=0))\n",
    "    vectors = torch.cat(training_vectors)\n",
    "\n",
    "    for p in final_untrained_fc.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in final_untrained_af.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    with torch.no_grad():\n",
    "        final_untrained_fc.weight.data = vectors\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(4096, 1024),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm1d(1024),\n",
    "        nn.Dropout(0.8),\n",
    "        nn.Linear(1024, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, NUM_ATTR),\n",
    "        nn.ReLU(),\n",
    "        final_untrained_fc,\n",
    "        final_untrained_af,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.7092411518096924\n",
      "Validation Loss: 2.7084641456604004\n",
      "Training Loss: 2.353914976119995\n",
      "Validation Loss: 2.4145851135253906\n",
      "Training Loss: 2.252676248550415\n",
      "Validation Loss: 2.3482372760772705\n",
      "Training Loss: 2.2158567905426025\n",
      "Validation Loss: 2.3300528526306152\n",
      "Training Loss: 2.161053419113159\n",
      "Validation Loss: 2.314211368560791\n",
      "Training Loss: 2.062382698059082\n",
      "Validation Loss: 2.296159029006958\n",
      "Training Loss: 2.0416183471679688\n",
      "Validation Loss: 2.3054888248443604\n",
      "Training Loss: 2.0135385990142822\n",
      "Validation Loss: 2.3002572059631348\n",
      "Training Loss: 2.065131187438965\n",
      "Validation Loss: 2.3012030124664307\n",
      "Training Loss: 1.9573040008544922\n",
      "Validation Loss: 2.297089099884033\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "glove_model = build_glove_model()\n",
    "train_model(glove_model, (x_train, y_train), (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ZERO SHOT LEARNING SCORE\n",
      "-> Top-5 Accuracy: 0.30\n",
      "-> Top-3 Accuracy: 0.16\n",
      "-> Top-1 Accuracy: 0.00\n"
     ]
    }
   ],
   "source": [
    "zsl_model = nn.Sequential(*list(model.children())[:-2])\n",
    "\n",
    "all_class_vectors = []\n",
    "\n",
    "for label in train_classes + zsl_classes:\n",
    "    all_class_vectors.append(glove[label].unsqueeze(dim=0))\n",
    "class_vectors = torch.cat(all_class_vectors)\n",
    "\n",
    "tree = KDTree(class_vectors)\n",
    "pred_zsl = zsl_model(torch.from_numpy(x_zsl))\n",
    "\n",
    "\n",
    "pred_zsl = pred_zsl.detach().numpy()\n",
    "top5, top3, top1 = 0, 0, 0\n",
    "\n",
    "for i, pred in enumerate(pred_zsl):\n",
    "    pred = np.expand_dims(pred, axis=0)\n",
    "    dist_5, index_5 = tree.query(pred, k=5)\n",
    "    pred_labels = [classnames[index] for index in index_5[0]]\n",
    "    true_label = y_zsl[i]\n",
    "\n",
    "    if true_label in pred_labels:\n",
    "        top5 += 1\n",
    "    if true_label in pred_labels[:3]:\n",
    "        top3 += 1\n",
    "    if true_label in pred_labels[0:1]:\n",
    "        top1 += 1\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"ZERO SHOT LEARNING SCORE\")\n",
    "print(\"-> Top-5 Accuracy: %.2f\" % (top5 / float(len(x_zsl))))\n",
    "print(\"-> Top-3 Accuracy: %.2f\" % (top3 / float(len(x_zsl))))\n",
    "print(\"-> Top-1 Accuracy: %.2f\" % (top1 / float(len(x_zsl))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eaf5a0339d8f4b7e9dca431d56be1af04904973cdd13b87e3fad863a5ec1aaf2"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}